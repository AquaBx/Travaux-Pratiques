{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# $\\color{blue}{\\text{TP 1 IIA : Prise en main}}$\n",
    "\n",
    "## <font color=\"#1abc9c\">Introduction</font>\n",
    "\n",
    "**Objectifs du TP :**\n",
    "\n",
    "Du point de vue des *savoirs-faire*, ce premier TP vise à se familiariser avec la manipulation des données en utilisant python et les librairies dédiées. Il s'agit de comprendre les formats de données utilisés, ainsi que les différentes commandes utiles et d'etre capable de les manipuler. Autrement dit, savoir les adapter à n'importe quel jeu de données.\n",
    "\n",
    "Du point de vue des *connaissances*, ce TP concerne les aspects méthodologiques : nécessité d'un ensemble de test, évaluation d'un classifieur. Il s'agit de comprendre et savoir interpréter les métriques retournées.\n",
    "\n",
    "L'analyse du jeu de données est également un point crucial dans la mise en oeuvre d'un processus d'apprentissage.\n",
    "\n",
    "**Présentation des principales librairies utilisées :**\n",
    "\n",
    "- numpy : outils fondamentaux de calcul scientifique. Définit les matrices multi-dimensionnelles et toutes les opérations de calcul algébrique et statistique associé\n",
    "- pandas : outil d'analyse et de manipulation de données\n",
    "- matplotlib : création de graphes\n",
    "- seaborn : librairie de visualisation de données (utilise pandas et matplotlib)\n",
    "- scikit-learn : la librairie la plus importante. C'est la librairie d'apprentissage : elle contient tous les algorithmes et outils nécessaires pour faire de l'analyse de données prédictive, que ce soit supervisé ou non, en classification ou en regression (basé sur numpy). Elle est très bien documentée (voir le User Guide et les APIs https://scikit-learn.org/stable/modules/classes.html)\n",
    "\n",
    "**Représentation des données dans scikit-learn:**\n",
    "\n",
    "Pour pouvoir utiliser les modèles implémentés dans scikit-learn, les données doivent être représentées dans un format spécifique : il s'agit de matrices (les exemples) ou de vecteurs (les cibles) au format numpy.\n",
    "\n",
    "<img src='http://people.irisa.fr/Ewa.Kijak/enseignement/iia/scikit_inputs.png' />\n",
    "\n",
    "Format des objets : numpy.ndarray\n",
    "\n",
    "<code>\n",
    "print(type(X))\n",
    "</code>\n",
    "\n",
    "<class 'numpy.ndarray'>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## <font color=\"#1abc9c\">1. Chargement et analyse des données</font>\n",
    "\n",
    "Nous allons utiliser dans ce TP un jeu de données pour une tache de **classification**.\n",
    "\n",
    "Il existe de nombreuses facons de charger un jeu de données. Certains jeux de données peuvent être chargés directement avec scikit learn :\n",
    "<code>\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "</code>\n",
    "Dans ce cas, (X, y) sont directement des *numpy array* et donc utilisables par scikit-learn.\n",
    "\n",
    "Nous utiliserons dans ces TPs la librairie *pandas* qui permet notamment de charger efficacement des fichiers csv. L'objet retourné est de type *pandas dataframe* et devra être converti ultérieurement en *numpy array* pour pouvoir utiliser scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iCSZdCMTHA4K",
    "outputId": "33e13b57-0bd6-4200-bdc4-bc8c86d54dcb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df=pd.read_csv('./data/Iris.csv', sep=',')\n",
    "\n",
    "# Affichage des 5 premieres lignes du dataframe\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PaHIg76ZHA4L",
    "outputId": "d07c9d7c-6d6a-4b2d-c2cb-62c7162d82df"
   },
   "outputs": [],
   "source": [
    "# Pandas propose de nombreuses fonctions pour analyser et décrire les données\n",
    "print(\"Résumé des données\")\n",
    "iris_df.info()\n",
    "print(\"\\n Statistiques\")\n",
    "print(iris_df.describe())\n",
    "print(\"\\n Nombre de valeurs uniques dans la colonne 'Species' et nombre d'instances prenant chacune de ces valeurs\")\n",
    "print(iris_df.Species.unique())\n",
    "print(iris_df.groupby('Species')[\"Id\"].count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "L'analyse du jeu de données est une étape préliminaire indispensable, pour comprendre les données et la tache, et pouvoir ensuite choisir un ou plusieurs modèles de facon pertinente.\n",
    "\n",
    "<font color=\"red\">**Question 1 :**</font>\n",
    "- Combien y'a-t-il d'exemples dans le jeu de données ?\n",
    "- Quelle est la variable cible ? Combien y'a-t-il de classes ? Quelles sont-elles ?\n",
    "- Combien y'a-t-il d'attributs ? Que représentent-ils ? Lesquels sont pertinents pour une tache de classification ?\n",
    "- Quelle est la répartition des exemples par classe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "$\\color{blue}{\\text{Remarque}}$ : pour cacher la sortie de l'execution, il suffit de double-cliquer à gauche de la sortie. Un nouveau clic fera ré-apparaitre la sortie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## <font color=\"#1abc9c\">2. Visualisation des données</font>\n",
    "\n",
    "Lorsque le nombre d'attributs le permet, il est toujours utile de pouvoir visualiser la distribution des données, notamment pour se rendre compte du degré de complexité de la tache de classification ou de regression.\n",
    "\n",
    "Lorsque le nombre d'attributs est très elevé, il faudra recourir à des outils de visualisation de données en grande dimension, basés sur la réduction de la dimension (ACP, t-SNE,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Wcefz31bHA4O",
    "outputId": "4150b009-60e9-4573-eff4-b8fa6a6f6733"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(iris_df, hue='Species', height=3, corner=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<font color=\"red\">**Question 2 :**</font> (Justifiez vos réponses).\n",
    "- Certaines paires d'attributs vous paraissent-elles mieux séparer les classes que d'autres ? \n",
    "- Certaines classes vous paraissent-elles plus faciles à caractériser ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## <font color=\"#1abc9c\">3. Préparation du jeu de données</font>\n",
    "\n",
    "**Etape 1 :** Il faut préparer les données pour qu'elles soient utilisables par scikit-learn, ie une matrice X pour les données et un vecteur y pour les labels (cf. intro) de type *numpy array*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plIViyV3HA4Q",
    "outputId": "a7de63f7-02ad-4bc6-8208-a413d40d327a"
   },
   "outputs": [],
   "source": [
    "dataset=iris_df.to_numpy() #convert the DataFrame to a NumPy array.\n",
    "X=dataset[:,1:5] # return cols from start_index to end_index – 1 and will include all rows\n",
    "y=dataset[:,5]\n",
    "\n",
    "# Verification des donnees produites\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Etape 2 :** Séparation du jeu de données en ensemble d'apprentissage et test.\n",
    "\n",
    "Une approche naive consiste à prendre par exemple les premiers 2/3 des exemples pour l'apprentissage et les 1/3 restants pour le test. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SY7NCb9xHA4R",
    "outputId": "002c8947-8229-4aa2-a26a-8ac10fdd5f74"
   },
   "outputs": [],
   "source": [
    "test_proportion = 1./3 # (holding out 33% of the data for testing)\n",
    "testset_size= (int)(test_proportion*len(X))\n",
    "trainset_size= (int)((1-test_proportion)*len(X))\n",
    "X_train = X[0:trainset_size]\n",
    "y_train = y[0:trainset_size]\n",
    "X_test = X[trainset_size:trainset_size+testset_size]\n",
    "y_test = y[trainset_size:trainset_size+testset_size]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 3a:**</font> Combien y'a-t-il d'exemples dans l'ensemble d'apprentissage ? de test ?\n",
    "\n",
    "<font color=\"red\">**Question 3b:**</font> Regardez la distribution des classes dans l'ensemble d'apprentissage et de test. Que constatez-vous ? Est-ce pertinent ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Une facon de procéder est de mélanger aléatoirement les données avant de les séparer (*\"shuffling\"*):\n",
    "<code>\n",
    "X_shuffle, y_shuffle = shuffle(X, y, random_state=0)    \n",
    "</code> \n",
    "\n",
    "On peut également utiliser une fonction de scikit-learn qui fait tout cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pHt1PflHA4T",
    "outputId": "0906cc24-bb86-4888-9ac8-3f9a04ff8942"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1./3, random_state = 1)\n",
    "\n",
    "# Verification du résultat\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(\"Stats on train target: \\n\", np.unique(y_train, return_counts=True))\n",
    "print(\"Stats on test target: \\n\", np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 3c:**</font> Quelle est la distribution des classes dans l'ensemble d'apprentissage et de test ? Est-ce pertinent ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## <font color=\"#1abc9c\">4. Apprentissage et évaluation d'un classifieur (modèle)</font>\n",
    "\n",
    "On utilise ici un classifieur (modèle) dont il n'est pas, pour l'instant, nécessaire de comprendre le fonctionnement. Le modèle est stocké dans un objet qu'on choisit d'appeler 'classifier'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIJP2rxUHA4U"
   },
   "outputs": [],
   "source": [
    "# Apprentissage du modèle sur les données d'entrainement\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 50)\n",
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.1 Accuracy\n",
    "\n",
    "*classifier* est le modèle appris sur les données d'apprentissage (fonction **fit()**). Il peut maintenant servir à prédire la classe de nouvelles données.\n",
    "\n",
    "La fonction **predict()** peut prendre en entrée 1 ou plusieurs exemples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TMh2wtUMHA4V",
    "outputId": "24dd8453-90df-4fd6-bbed-e8a93210e511"
   },
   "outputs": [],
   "source": [
    "# prediction de la classe pour l'exemple x=[5, 5, 3, 2]\n",
    "sample = [[5, 5, 3, 2]]\n",
    "pred = classifier.predict(sample)\n",
    "print(\"classe prédite :\", pred)\n",
    "\n",
    "# prediction de la classe pour 2 exemples x(1) et x(2)\n",
    "samples = [[5.7, 2.8, 3.6, 1.21], [4.8, 3.5, 2.9, 1.86]]\n",
    "pred = classifier.predict(samples)\n",
    "print(\"classes prédites :\", pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Bien entendu, pour vérifier si la classification est correcte, il faut disposer de la vérité terrain, ce qui est le cas pour l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRUpsGS6HA4W",
    "outputId": "4e63f6d0-90d3-42e1-991e-6ee47ad9171b"
   },
   "outputs": [],
   "source": [
    "# prediction pour le 2eme exemple de l'ensemble de test\n",
    "y_pred_sample = classifier.predict([X_test[1,:]])\n",
    "print(y_pred_sample)\n",
    "print(y_test[1])\n",
    "\n",
    "# predictions pour l'ensemble de test\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 4:**</font> comparer (manuellement) les classes prédites avec les classes vraies. Combien de fois le classifieur se trompe-t-il ?\n",
    "\n",
    "Scikit learn permet de calculer l'accuracy du modèle.\n",
    "\n",
    "<font color=\"red\">**Question 5:**</font> Que représente cette valeur ? Comment est-elle calculée ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EgQPIKiHA4X",
    "outputId": "2f402700-54be-494b-ae2c-1438d759df79"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# TODO: calculez l'erreur réelle et l'erreur empirique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 6:**</font> Donnez l'erreur empirique et l'erreur réelle (en ajoutant les lignes de codes nécessaires). Que représentent-elles ? Quelles sont leur utilité ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.2 Matrice de confusion\n",
    "\n",
    "La matrice de confusion est un meilleur outil pour analyser les résultats et le comportement d'un classifieur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdKih0ZrHA4X",
    "outputId": "4bf547d6-d96e-4597-8836-71bbefce8ded"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, y_pred) # Attention à l'ordre des arguments qui détermine la signification des lignes et des colonnes de la matrice !\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 7:**</font> A quoi correspondent les lignes et les colonnes de cette matrice ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "nDODfW8NHA4Y",
    "outputId": "2d71a289-b71c-4313-f820-24196113fbe8"
   },
   "outputs": [],
   "source": [
    "# On peut obtenir une meilleure visualisation de cette matrice\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(conf, square=True, annot=True, cbar=False\n",
    "       , xticklabels=np.unique(y_test)\n",
    "       , yticklabels=np.unique(y_test))\n",
    "plt.xlabel('valeurs prédites')\n",
    "plt.ylabel('valeurs réelles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 8:**</font> \n",
    "- Retrouvez la valeur de l'accuracy à partir de cette matrice\n",
    "- Quelle est la precision pour la classe 'Iris-virginica' ?\n",
    "- Quel est le rappel pour la classe 'Iris-virginica' ?\n",
    "- Quelle est la classe qui a le meilleur rappel ? Qu'est-ce que cela signifie ?\n",
    "- Quelle est la classe qui a la plus faible précision ? Qu'est-ce que cela signifie ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.3 Frontière de decision\n",
    "\n",
    "La visualisation de la frontière de décision n'est possible qu'en 2D. S'il y a plus d'attributs, cela implique de sélectionner 2 attributs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "11dJLPxLHA4Z",
    "outputId": "a3c915d0-11a6-46be-86de-b883f2bd426d"
   },
   "outputs": [],
   "source": [
    "import tpiia_utils\n",
    "from sklearn import preprocessing\n",
    "\n",
    "### Convert label to values with scikit-learn - needed for visualisation fonction\n",
    "enc = preprocessing.LabelEncoder()\n",
    "yv= enc.fit_transform(y)\n",
    "\n",
    "Xplot=X[:,[0,1]] # on sélectionne les 2 premiers attributs dans le jeu de données\n",
    "# autre syntaxe possible : Xplot=X[:,0:2] \n",
    "\n",
    "# On doit apprendre un classifieur qui ne prend que les 2 variables selectionnées en entrée\n",
    "Xplot_train, Xplot_test, yplot_train, yplot_test = train_test_split(Xplot, yv, test_size = 1./3, random_state = 1)\n",
    "classifier_plot = KNeighborsClassifier(n_neighbors = 50)\n",
    "classifier_plot.fit(Xplot_train, yplot_train);\n",
    "\n",
    "# Fonction de visualisation de la frontiere de decision\n",
    "tpiia_utils.plot_boundary(classifier_plot, Xplot_test, yplot_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 9:**</font> Repérez visuellement les exemples mal classés, Combien en comptez-vous ?\n",
    "\n",
    "<font color=\"red\">**Question 10:**</font> \n",
    "- Calculez l'accuracy du nouveau classifieur 'classifieur_plot'.\n",
    "- Recommencez avec d'autres couples d'attributs. \n",
    "- Indiquez les résultats obtenus sous forme de tableau : couples attributs/accuracy. \n",
    "- Quel est le couple d'attributs le plus informatif pour la classification ? \n",
    "- Cela rejoint-il votre observation de la question 2 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Db0KL_AlNNPU",
    "outputId": "e79cf2d1-7201-4b7d-9ea2-75f86ff1ff5c"
   },
   "outputs": [],
   "source": [
    "# TODO: calculez l'accuracy du nouveau classifieur 'classifieur_plot'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.4 Validation croisée\n",
    "\n",
    "Supposons que l'on apprenne les paramètres du classifieur sur des ensembles d'apprentissage et de test différents.\n",
    "\n",
    "Cela peut se faire en modifiant la graine du générateur (pseudo-)aléatoire ('random_state') qui va déterminer quels exemples sont tirés lors de la séparation du jeu de données.\n",
    "\n",
    "**A faire :** Utilisez l'exemple jouet ci-dessous pour bien comprendre l'effet de la variable ('random_state'):\n",
    "- générer des échantillons d'apprentissage et de test avec 'random_state=1'\n",
    "- modifier la valeur de 'random_state' : qu'observez-vous ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random_state toy example\n",
    "# Toy dataset creation\n",
    "X_toy=range(1,11)\n",
    "y_toy=[1,1,1,1,1,1,0,0,0,0]\n",
    "print(\"small data toy: \",list(X_toy))\n",
    "# Split with 'random_state = 1'\n",
    "X_train_toy1, X_test_toy1, y_train_toy1, y_test_toy1 = train_test_split(X_toy, y_toy, test_size = 1./3, random_state = 1)\n",
    "print(\"train_set1 :\", X_train_toy1)\n",
    "print(\"test_set1 :\", X_test_toy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79-QtJHsHA4a",
    "outputId": "3b2a0d3b-184f-4773-941d-c8b9494c452a"
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size = 1./3, random_state = 1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size = 1./3, random_state = 20)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size = 1./3, random_state = 34)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size = 1./3, random_state = 45)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size = 1./3, random_state = 103)\n",
    "\n",
    "classifier.fit(X_train1, y_train1);\n",
    "y_pred1 = classifier.predict(X_test1)\n",
    "print(\"Accuracy on test1:\", metrics.accuracy_score(y_test1, y_pred1))\n",
    "\n",
    "classifier.fit(X_train2, y_train2);\n",
    "y_pred2 = classifier.predict(X_test2)\n",
    "print(\"Accuracy on test2:\", metrics.accuracy_score(y_test2, y_pred2))\n",
    "\n",
    "classifier.fit(X_train3, y_train3);\n",
    "y_pred3 = classifier.predict(X_test3)\n",
    "print(\"Accuracy on test3:\", metrics.accuracy_score(y_test3, y_pred3))\n",
    "\n",
    "classifier.fit(X_train4, y_train4);\n",
    "y_pred4 = classifier.predict(X_test4)\n",
    "print(\"Accuracy on test4:\", metrics.accuracy_score(y_test4, y_pred4))\n",
    "\n",
    "classifier.fit(X_train5, y_train5);\n",
    "y_pred5 = classifier.predict(X_test5)\n",
    "print(\"Accuracy on test5:\", metrics.accuracy_score(y_test5, y_pred5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 11:**</font> Qu'observez-vous ? Quel problème est illustré en modifiant la graine ? Que peut-on dire de la performance du modèle choisi ?\n",
    "\n",
    "<font color=\"red\">**Question 12:**</font> Rappelez le principe de la validation croisée à k plis. Que permet cette procédure ?\n",
    "\n",
    "La validation croisée est implémentée dans scikit-learn. Il y a plusieurs façons de la faire, la plus compacte est donnée ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oett7fzeo8_Z",
    "outputId": "bdc8e5cb-86c0-4144-cac7-5b8b17ae2f8d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(classifier, X, y, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 13:**</font> Que retourne 'cross_val_score' ? Combien y'a-t-il de plis ici ?\n",
    "\n",
    "On peut obtenir le score moyen, ainsi que l'écart-type :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J4HRPBusW0Q",
    "outputId": "6e8b7fdc-0064-4ff5-b9d2-205377cd2761"
   },
   "outputs": [],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## <font color=\"#1abc9c\">5. Pré-traitement des données</font>\n",
    "\n",
    "Pour certains modèles, la transformation des données (on parle de pré-traitement) est indispensable, en particulier lorsque les attributs ont des ordres de grandeurs différents et que le modèle se base sur des calculs de distance entre les exemples (distance dans l'espace des attributs, soit, un espace vectoriel de dimension d). Cela accélère également parfois la convergence d'algorithmes comme la descente de gradient.\n",
    "\n",
    "Les principaux pré-traitements sont les suivants :\n",
    "\n",
    "- binarisation\n",
    "- centrer et réduire\n",
    "- scaling\n",
    "- normalization L2\n",
    "\n",
    "Ils sont illustrés ci-dessous sur un jeu de données jouet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1f58o5NHA4b",
    "outputId": "3eb7fb49-7ad9-4077-f60a-2721a1d7c8bc"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "input_data = np.array(\n",
    "   [[2.1, -1.9, 5.5],\n",
    "   [-1.5, 2.4, 3.5],\n",
    "   [0.5, -7.9, 5.6],\n",
    "   [5.9, 2.3, -5.8]])\n",
    "\n",
    "data_binarized = preprocessing.Binarizer(threshold=0.5).transform(input_data)\n",
    "print(\"\\nBinarized data:\\n\", data_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozqBoZBzHA4b",
    "outputId": "1a8d428d-e368-467c-a55c-efb777e31a0d"
   },
   "outputs": [],
   "source": [
    "#displaying the mean and the standard deviation of the input data\n",
    "print(\"Mean =\", input_data.mean(axis=0)) # axis=0 -> selon les colonnes\n",
    "print(\"Stddeviation = \", input_data.std(axis=0))\n",
    "\n",
    "#Removing the mean and the standard deviation of the input data\n",
    "data_scaled = preprocessing.scale(input_data)\n",
    "print(\"Mean_removed =\", data_scaled.mean(axis=0))\n",
    "print(\"Stddeviation_removed =\", data_scaled.std(axis=0))\n",
    "print(\"\\nScaled data:\\n\", data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNjVrC_PHA4b",
    "outputId": "f5534666-761b-4861-ae9e-69955b5c00fd"
   },
   "outputs": [],
   "source": [
    "data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "data_scaled_minmax = data_scaler_minmax.fit_transform(input_data)\n",
    "print (\"\\nMin max scaled data:\\n\", data_scaled_minmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0rtEAhiHA4c",
    "outputId": "b3d65325-5107-46c0-dcb4-61d8e2f7c47e"
   },
   "outputs": [],
   "source": [
    "data_normalized=preprocessing.Normalizer().fit_transform(input_data)\n",
    "print (\"\\nL2 Normalized data:\\n\", data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 14:**</font> Résumez en une phrase l'effet de chaque pré-traitement sur les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color=\"red\">**Question 15:**</font> Appliquer les pré-traitements qui vous semblent pertinents sur le jeu de données et calculer l'accuracy (erreur réelle) obtenue par le modèle.\n",
    "\n",
    "Comparer avec l'accuracy sans pré-traitements. Vous présenterez les résultats sous forme de tableau.\n",
    "\n",
    "L'un des pré-traitements améliore-t-il les résultats ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6_72xKe0dMR",
    "outputId": "cabb4213-c270-4e8f-d751-7a780837fb50"
   },
   "outputs": [],
   "source": [
    "# TODO: Sélectionner et adapter ici les 6 à 8 lignes de code permettant de calculer l'accuracy sur le jeu de donnée en lui appliquant un pré-traitement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## <font color=\"#1abc9c\">6. Etude d'un autre jeu de données (Facultatif)</font>\n",
    "\n",
    "Réitérer l'ensemble de l'analyse en utilisant le jeu de données : breast_cancer.csv, dont la description est fournie dans le fichier breast_cancer_description.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "colab": {
   "collapsed_sections": [],
   "name": "tp1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
